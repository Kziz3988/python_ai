{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aefe355",
   "metadata": {},
   "source": [
    "# <center>基于相关滤波器的目标跟踪</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7feb04",
   "metadata": {},
   "source": [
    "## 视频预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da04ee22",
   "metadata": {},
   "source": [
    "输入一个视频，将其转换为图像序列，并转灰度图以便进一步处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa386cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import cv2\n",
    "\n",
    "#显示RGB图像\n",
    "def show_image(image):\n",
    "    image_plt = copy.deepcopy(image)\n",
    "    image_plt = image_plt.permute(1, 2, 0)\n",
    "    plt.imshow(image_plt)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#显示灰度图像\n",
    "def show_gray_image(image):\n",
    "    image_plt = copy.deepcopy(image)\n",
    "    image_plt = image_plt.squeeze()\n",
    "    plt.imshow(image_plt, cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#RGB转灰度\n",
    "def rgb_to_gray(image):\n",
    "    transform = transforms.Grayscale(num_output_channels = 1)\n",
    "    image_out = transform(image)\n",
    "    return image_out\n",
    "\n",
    "#从本地文件加载视频\n",
    "def load_video(output_path = './output', frameInterval = 1):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    filepath = filedialog.askopenfilename(title = \"请选择待追踪的视频\", filetypes = [(\"Video Files\", \"*.mp4\")])\n",
    "    if filepath:\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        else:\n",
    "            for filename in os.listdir(output_path):\n",
    "                file = os.path.join(output_path, filename)\n",
    "                if os.path.isfile(file) or os.path.islink(file):\n",
    "                    os.unlink(file)\n",
    "                elif os.path.isdir(file):\n",
    "                    shutil.rmtree(file)\n",
    "        camera = cv2.VideoCapture(filepath)\n",
    "        index = 0\n",
    "        count = 0\n",
    "        while True:\n",
    "            res, image = camera.read()\n",
    "            if not res:\n",
    "                break\n",
    "            if count % frameInterval == 0:\n",
    "                cv2.imwrite(output_path + str(index) + '.png', image)\n",
    "                index += 1\n",
    "            count += 1\n",
    "        camera.release()\n",
    "        return True, index\n",
    "    else:\n",
    "        return False, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d242b35",
   "metadata": {},
   "source": [
    "## 图像预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63a8cd",
   "metadata": {},
   "source": [
    "实现余弦窗和高斯滤波器，对目标区域进行预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e438c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成高斯滤波器\n",
    "def gaussian_kernel(width, height, sigma = 2):\n",
    "    kernel = numpy.zeros((1, height, width))\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            kernel[0, y, x] = numpy.exp(-((((height - 1) / 2 - y) ** 2 + ((width - 1) / 2 - x) ** 2) / (2 * sigma ** 2)))\n",
    "    kernel /= numpy.sum(kernel)\n",
    "    return kernel\n",
    "\n",
    "#生成余弦窗口\n",
    "def cos_window(width, height):\n",
    "    kernel = numpy.zeros((height, width))\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            kernel[y, x] = numpy.sin(numpy.pi * x / (width - 1)) * numpy.sin(numpy.pi * y / (height - 1))\n",
    "            #处理浮点数精度问题\n",
    "            if kernel[y, x] < 1e-15:\n",
    "                kernel[y, x] = 0.0\n",
    "    return kernel\n",
    "\n",
    "#图像预处理\n",
    "def preprocess(image, epsilon = 1e-5):\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image_out = Image.fromarray(image.numpy().astype('uint8'))\n",
    "    elif isinstance(image, Image.Image):\n",
    "        image_out = image\n",
    "    else:\n",
    "        image_out = Image.fromarray(image.astype('uint8'))\n",
    "    transform = transforms.Compose([transforms.PILToTensor(), transforms.Grayscale(num_output_channels = 1)])\n",
    "    image_out = transform(image_out)\n",
    "    image_out = image_out.to(torch.float)\n",
    "    image_out /= 255\n",
    "    image_out = torch.squeeze(image_out, 0)\n",
    "    height, width = image_out.shape[-2:]\n",
    "    image_out = torch.log(image_out + 1) #对图像取对数，降低背景噪声\n",
    "    image_out = (image_out - torch.mean(image_out)) / (torch.std(image_out) + epsilon) #归一化\n",
    "    image_out = torch.tensor(cos_window(width, height)) * image_out #降低频谱泄漏\n",
    "    image_out = (torch.unsqueeze(image_out, 0)).numpy()\n",
    "    return image_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb1812",
   "metadata": {},
   "source": [
    "## 确定目标初始位置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42626324",
   "metadata": {},
   "source": [
    "用户在视频第一帧画出一个矩形框，表示待跟踪目标的位置。在实际应用中可以搭配YOLO等目标检测算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4547df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制矩形框并保存\n",
    "def draw_rect(input_path, rect, color):\n",
    "    image = cv2.imread(input_path)\n",
    "    cv2.rectangle(image, (int(rect[0]), int(rect[1])), (int(rect[0] + rect[2]), int(rect[1] + rect[3])), color, 1)\n",
    "    cv2.imwrite(input_path, image)\n",
    "\n",
    "#使用opencv库提供的RoI选择\n",
    "def select_target(path):\n",
    "    image = cv2.imread(path)\n",
    "    rect = cv2.selectROI(\"Press enter to select target\", image)\n",
    "    if rect[2] == 0 or rect[3] == 0: #未选择有效的范围\n",
    "        return False, None, None\n",
    "    cv2.destroyAllWindows()\n",
    "    #截取选中的区域并预处理\n",
    "    target = image[int(rect[1]):int(rect[1] + rect[3]), int(rect[0]):int(rect[0] + rect[2])]\n",
    "    target = Image.fromarray(cv2.cvtColor(target, cv2.COLOR_BGR2RGB)) #opencv图像转PIL\n",
    "    target = preprocess(target)\n",
    "    return True, rect, target\n",
    "\n",
    "#仿射变换时的镜像反射\n",
    "def border_reflect(n, border):\n",
    "    if n < 0:\n",
    "        return -n\n",
    "    elif n >= border:\n",
    "        return 2 * border - n - 1\n",
    "    else:\n",
    "        return n\n",
    "\n",
    "#对目标进行随机重定位\n",
    "def random_warp(image, rand = 0.1):\n",
    "    height, width = image.shape[-2:]\n",
    "    if image.ndim == 3:\n",
    "        image = image[0]\n",
    "    angle = numpy.random.uniform(-rand, rand)\n",
    "    c, s = numpy.cos(angle), numpy.sin(angle)\n",
    "    warp_mat = numpy.array([[c + numpy.random.uniform(-rand, rand), -s + numpy.random.uniform(-rand, rand), 0],\n",
    "                  [s + numpy.random.uniform(-rand, rand), c + numpy.random.uniform(-rand, rand), 0]])\n",
    "    center_warp = numpy.array([[width / 2], [height / 2]])\n",
    "    tmp = numpy.sum(warp_mat[:, :2], axis = 1).reshape((2, 1))\n",
    "    warp_mat[:, 2:] = center_warp - center_warp * tmp\n",
    "    #仿射变换\n",
    "    image_out = numpy.zeros((height, width))\n",
    "    for v in range(height):\n",
    "        for u in range(width):\n",
    "            x = border_reflect(round(warp_mat[0][0] * u + warp_mat[0][1] * v + warp_mat[0][2]), width)\n",
    "            y = border_reflect(round(warp_mat[1][0] * u + warp_mat[1][1] * v + warp_mat[1][2]), height)\n",
    "            image_out[v][u] = image[y][x]\n",
    "    return image_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104e33d",
   "metadata": {},
   "source": [
    "## 更新目标位置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c9e18",
   "metadata": {},
   "source": [
    "通过目标响应的最大值确定目标在当前帧的位置。采用傅立叶变换来加快计算速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4531f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化相关滤波器\n",
    "def init_corr_filter(target, warp_time = 8):\n",
    "    height, width = target.shape[-2:]\n",
    "    a = numpy.zeros((1, height, width), dtype = \"complex128\")\n",
    "    b = numpy.zeros((1, height, width), dtype = \"complex128\")\n",
    "    g = numpy.fft.fft2(gaussian_kernel(width, height)) #初始目标响应\n",
    "    for i in range(warp_time): #多次随机重定位后确定初始相关滤波器\n",
    "        image_out = random_warp(target)\n",
    "        f = numpy.fft.fft2(preprocess(image_out))\n",
    "        a += g * numpy.conj(f)\n",
    "        b += f * numpy.conj(f)\n",
    "    return a, b, g\n",
    "\n",
    "#更新相关滤波器和目标位置\n",
    "def update_corr_filter(image, target_rect, a, b, gaussian, eta = 0.125):\n",
    "    height = target_rect[3]\n",
    "    width = target_rect[2]\n",
    "    h = a / b #相关滤波器\n",
    "    target = image[int(target_rect[1]):int(target_rect[1] + target_rect[3]), int(target_rect[0]):int(target_rect[0] + target_rect[2])]\n",
    "    f = preprocess(target)\n",
    "    g = h * numpy.fft.fft2(f)\n",
    "    g = numpy.real(numpy.fft.ifft2(g)) #目标响应\n",
    "    cur_pos = numpy.unravel_index(numpy.argmax(g, axis = None), g.shape) #目标响应最大值位置是当前帧的目标位置\n",
    "    psr = (numpy.max(g) + numpy.mean(g)) / numpy.std(g) #使用峰值旁瓣比来量化目标跟踪效果\n",
    "    offset_x = cur_pos[2] - width // 2\n",
    "    offset_y = cur_pos[1] - height // 2\n",
    "    rect = [target_rect[0] + offset_x, target_rect[1] + offset_y, target_rect[2], target_rect[3]]\n",
    "    target = image[int(rect[1]):int(rect[1] + rect[3]), int(rect[0]):int(rect[0] + rect[2])]\n",
    "    f = preprocess(target)\n",
    "    f = numpy.fft.fft2(f)\n",
    "    a_ = eta * (gaussian * numpy.conj(f)) + (1 - eta) * a #求相关相当于旋转180度（即复共轭）后求卷积\n",
    "    b_ = eta * (f * numpy.conj(f)) + (1 - eta) * b\n",
    "    return rect, a_, b_, psr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f63f52",
   "metadata": {},
   "source": [
    "## 输出目标跟踪视频"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417ba98",
   "metadata": {},
   "source": [
    "在图像序列中标注出目标位置，并生成视频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650f61e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目标初始位置：(1028,519)\n",
      "第1帧位置：(1038,528)，目标可能丢失\n",
      "第2帧位置：(1038,528)，目标可能丢失\n",
      "第3帧位置：(1038,528)，目标可能丢失\n",
      "第4帧位置：(1038,528)，目标可能丢失\n",
      "第5帧位置：(1038,528)，目标可能丢失\n",
      "第6帧位置：(1038,528)，目标可能丢失\n",
      "第7帧位置：(1038,528)，目标跟踪正常\n",
      "第8帧位置：(1038,528)，目标跟踪正常\n",
      "第9帧位置：(1038,528)，目标跟踪正常\n",
      "第10帧位置：(1038,528)，目标跟踪正常\n",
      "第11帧位置：(1038,528)，目标跟踪正常\n",
      "第12帧位置：(1038,528)，目标跟踪正常\n",
      "第13帧位置：(1038,528)，目标跟踪正常\n",
      "第14帧位置：(1038,528)，目标跟踪正常\n",
      "第15帧位置：(1038,528)，目标跟踪正常\n",
      "第16帧位置：(1039,526)，目标跟踪正常\n",
      "第17帧位置：(1045,539)，目标可能丢失\n",
      "第18帧位置：(1045,538)，目标可能丢失\n",
      "第19帧位置：(1046,538)，目标可能丢失\n",
      "第20帧位置：(1046,538)，目标跟踪正常\n",
      "第21帧位置：(1046,538)，目标跟踪正常\n",
      "第22帧位置：(1046,538)，目标跟踪正常\n",
      "第23帧位置：(1046,538)，目标跟踪正常\n",
      "第24帧位置：(1046,538)，目标跟踪正常\n",
      "第25帧位置：(1046,538)，目标跟踪正常\n",
      "第26帧位置：(1046,538)，目标跟踪正常\n",
      "第27帧位置：(1046,538)，目标跟踪正常\n",
      "第28帧位置：(1046,538)，目标跟踪正常\n",
      "第29帧位置：(1046,538)，目标跟踪正常\n",
      "第30帧位置：(1046,538)，目标跟踪正常\n",
      "第31帧位置：(1046,538)，目标跟踪正常\n",
      "第32帧位置：(1046,538)，目标跟踪正常\n",
      "第33帧位置：(1046,538)，目标跟踪正常\n",
      "第34帧位置：(1046,538)，目标跟踪正常\n",
      "第35帧位置：(1046,538)，目标跟踪正常\n",
      "第36帧位置：(1046,538)，目标跟踪正常\n",
      "第37帧位置：(1046,539)，目标跟踪正常\n",
      "第38帧位置：(1046,539)，目标跟踪正常\n",
      "第39帧位置：(1057,543)，目标可能丢失\n",
      "第40帧位置：(1036,541)，目标可能丢失\n",
      "第41帧位置：(1043,510)，目标可能丢失\n",
      "第42帧位置：(1044,517)，目标可能丢失\n",
      "第43帧位置：(1057,491)，目标可能丢失\n",
      "第44帧位置：(1057,491)，目标可能丢失\n",
      "第45帧位置：(1067,504)，目标可能丢失\n",
      "第46帧位置：(1056,507)，目标可能丢失\n",
      "第47帧位置：(1048,496)，目标可能丢失\n",
      "第48帧位置：(1050,486)，目标可能丢失\n",
      "第49帧位置：(1049,492)，目标可能丢失\n",
      "第50帧位置：(1049,492)，目标跟踪正常\n",
      "第51帧位置：(1049,498)，目标跟踪正常\n",
      "第52帧位置：(1034,496)，目标可能丢失\n",
      "第53帧位置：(1035,497)，目标跟踪正常\n",
      "第54帧位置：(1044,500)，目标可能丢失\n",
      "第55帧位置：(1055,501)，目标可能丢失\n",
      "第56帧位置：(1055,501)，目标跟踪正常\n",
      "第57帧位置：(1053,497)，目标跟踪正常\n",
      "第58帧位置：(1042,487)，目标可能丢失\n",
      "第59帧位置：(1060,488)，目标跟踪正常\n",
      "第60帧位置：(1076,489)，目标跟踪正常\n",
      "第61帧位置：(1076,486)，目标跟踪正常\n",
      "第62帧位置：(1076,486)，目标跟踪正常\n",
      "第63帧位置：(1071,478)，目标可能丢失\n",
      "第64帧位置：(1066,486)，目标可能丢失\n",
      "第65帧位置：(1071,473)，目标跟踪正常\n",
      "第66帧位置：(1071,469)，目标可能丢失\n",
      "第67帧位置：(1055,448)，目标可能丢失\n",
      "第68帧位置：(1055,448)，目标跟踪正常\n",
      "第69帧位置：(1045,449)，目标跟踪正常\n",
      "第70帧位置：(1045,449)，目标跟踪正常\n",
      "第71帧位置：(1053,452)，目标跟踪正常\n",
      "第72帧位置：(1051,451)，目标跟踪正常\n",
      "第73帧位置：(1043,447)，目标跟踪正常\n",
      "第74帧位置：(1043,447)，目标跟踪正常\n",
      "第75帧位置：(1056,451)，目标跟踪正常\n",
      "第76帧位置：(1071,457)，目标可能丢失\n",
      "第77帧位置：(1086,464)，目标跟踪正常\n",
      "第78帧位置：(1086,466)，目标跟踪正常\n",
      "第79帧位置：(1098,471)，目标跟踪正常\n",
      "第80帧位置：(1098,471)，目标跟踪正常\n",
      "第81帧位置：(1113,476)，目标可能丢失\n",
      "第82帧位置：(1121,481)，目标跟踪正常\n",
      "第83帧位置：(1134,468)，目标可能丢失\n",
      "第84帧位置：(1132,440)，目标可能丢失\n",
      "第85帧位置：(1141,452)，目标可能丢失\n",
      "第86帧位置：(1141,452)，目标跟踪正常\n",
      "第87帧位置：(1135,442)，目标跟踪正常\n",
      "第88帧位置：(1135,442)，目标跟踪正常\n",
      "第89帧位置：(1136,452)，目标可能丢失\n",
      "第90帧位置：(1153,466)，目标可能丢失\n",
      "第91帧位置：(1149,445)，目标可能丢失\n",
      "第92帧位置：(1149,445)，目标跟踪正常\n",
      "第93帧位置：(1169,450)，目标可能丢失\n",
      "第94帧位置：(1175,452)，目标跟踪正常\n",
      "第95帧位置：(1168,458)，目标可能丢失\n",
      "第96帧位置：(1170,459)，目标可能丢失\n",
      "第97帧位置：(1182,458)，目标跟踪正常\n",
      "第98帧位置：(1182,458)，目标跟踪正常\n",
      "第99帧位置：(1185,457)，目标可能丢失\n",
      "第100帧位置：(1181,465)，目标可能丢失\n",
      "第101帧位置：(1186,473)，目标可能丢失\n",
      "第102帧位置：(1187,479)，目标跟踪正常\n",
      "第103帧位置：(1179,479)，目标可能丢失\n",
      "第104帧位置：(1179,479)，目标跟踪正常\n",
      "第105帧位置：(1175,483)，目标跟踪正常\n",
      "第106帧位置：(1185,476)，目标跟踪正常\n",
      "第107帧位置：(1189,476)，目标跟踪正常\n",
      "第108帧位置：(1183,476)，目标跟踪正常\n",
      "第109帧位置：(1186,481)，目标跟踪正常\n",
      "第110帧位置：(1186,481)，目标跟踪正常\n",
      "第111帧位置：(1195,486)，目标可能丢失\n",
      "第112帧位置：(1208,484)，目标跟踪正常\n",
      "第113帧位置：(1208,488)，目标跟踪正常\n",
      "第114帧位置：(1205,488)，目标跟踪正常\n",
      "第115帧位置：(1202,496)，目标跟踪正常\n",
      "第116帧位置：(1202,496)，目标跟踪正常\n",
      "第117帧位置：(1199,489)，目标可能丢失\n",
      "第118帧位置：(1191,497)，目标跟踪正常\n",
      "第119帧位置：(1202,528)，目标可能丢失\n",
      "第120帧位置：(1208,517)，目标可能丢失\n",
      "第121帧位置：(1211,520)，目标可能丢失\n",
      "第122帧位置：(1211,520)，目标跟踪正常\n",
      "第123帧位置：(1212,494)，目标可能丢失\n",
      "第124帧位置：(1213,492)，目标可能丢失\n",
      "第125帧位置：(1213,486)，目标跟踪正常\n",
      "第126帧位置：(1232,483)，目标跟踪正常\n",
      "第127帧位置：(1240,477)，目标可能丢失\n",
      "第128帧位置：(1240,477)，目标跟踪正常\n",
      "第129帧位置：(1250,474)，目标跟踪正常\n",
      "第130帧位置：(1258,470)，目标跟踪正常\n",
      "第131帧位置：(1257,466)，目标跟踪正常\n",
      "第132帧位置：(1255,459)，目标跟踪正常\n",
      "第133帧位置：(1251,456)，目标跟踪正常\n",
      "第134帧位置：(1251,456)，目标跟踪正常\n",
      "第135帧位置：(1247,456)，目标跟踪正常\n",
      "第136帧位置：(1246,456)，目标跟踪正常\n",
      "第137帧位置：(1244,455)，目标跟踪正常\n",
      "第138帧位置：(1238,453)，目标跟踪正常\n",
      "第139帧位置：(1248,465)，目标跟踪正常\n",
      "第140帧位置：(1248,465)，目标跟踪正常\n",
      "第141帧位置：(1248,459)，目标跟踪正常\n",
      "第142帧位置：(1248,463)，目标跟踪正常\n",
      "第143帧位置：(1249,465)，目标跟踪正常\n",
      "第144帧位置：(1264,450)，目标可能丢失\n",
      "第145帧位置：(1296,431)，目标跟踪正常\n",
      "第146帧位置：(1296,431)，目标跟踪正常\n",
      "第147帧位置：(1315,398)，目标可能丢失\n",
      "第148帧位置：(1349,401)，目标可能丢失\n",
      "第149帧位置：(1354,381)，目标可能丢失\n",
      "第150帧位置：(1359,394)，目标可能丢失\n",
      "第151帧位置：(1371,387)，目标可能丢失\n",
      "第152帧位置：(1371,387)，目标跟踪正常\n"
     ]
    }
   ],
   "source": [
    "output_path = './output/'\n",
    "flag1, frames = load_video(output_path, 5)\n",
    "green = (0, 255, 0)\n",
    "red = (0, 0, 255)\n",
    "threshold = 7\n",
    "if flag1:\n",
    "    flag2, rect, target = select_target(output_path + \"0.png\")\n",
    "    print(\"目标初始位置：({},{})\".format(rect[0] + rect[2] // 2, rect[1] + rect[3] // 2))\n",
    "    draw_rect(output_path + \"0.png\", rect, green)\n",
    "    if flag2:\n",
    "        #生成图像序列\n",
    "        a, b, g = init_corr_filter(target)\n",
    "        for i in range(1, frames):\n",
    "            image = cv2.imread(output_path + str(i) + \".png\")\n",
    "            rect, a, b, psr = update_corr_filter(image, rect, a, b, g)\n",
    "            if psr < threshold:\n",
    "                state = \"目标可能丢失\"\n",
    "                draw_rect(output_path + str(i) + \".png\", rect, red)\n",
    "            else:\n",
    "                state = \"目标跟踪正常\"\n",
    "                draw_rect(output_path + str(i) + \".png\", rect, green)\n",
    "            print(\"第{}帧位置：({},{})，{}\".format(i, rect[0] + rect[2] // 2, rect[1] + rect[3] // 2, state))\n",
    "        \n",
    "        #生成视频\n",
    "        frame = cv2.imread(output_path + \"0.png\")\n",
    "        height, width, _ = frame.shape\n",
    "        video = cv2.VideoWriter(output_path + \"output.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n",
    "        video.write(frame)\n",
    "        for i in range(1, frames):\n",
    "            frame = cv2.imread(output_path + str(i) + \".png\")\n",
    "            video.write(frame)\n",
    "        video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
